from bgraph.types import (Optional, OutChoice, QueryType, Section, SectionNode, Union, all_module_types,
                          is_defaults_module, get_backend_suffixed_names, setup_up_down_dependency, find_deep_dict,
                          check_host_supported_matching, check_if_cc_bin_unmatching, check_target_matching,
                          excluded_section_types, depends_on_impl, getSectionKey, has_invalid_target_arch,
                          check_section_name_matching, is_ndk_enabled_section, has_backend_dict, check_name_matching, excluded_sub_types)
import argparse
import collections
import logging
import pathlib
import pickle
from enum import Enum
# import enum
from pathlib import Path
from typing import Dict, List, Set, Sequence, Tuple, IO, Any

import re
import cmd2
import rich.console
import rich.filesize
import rich.table
import typer
from cmd2 import (Bg, Cmd2ArgumentParser, Fg, style, with_argparser)

import networkx as nx  # type: ignore
from networkx.drawing.nx_agraph import graphviz_layout

import bgraph
import bgraph.exc
import bgraph.utils
from bgraph.backup import get_aosp_root, test_subdirs, backup_module, gen_backup_path, restore_module, is_normal_module_path, is_backup_module_path, conv_to_normal_path, conv_to_backup_path

import matplotlib.pyplot as plt
from natsort import natsort_key

class DependType(Enum):
    UP = 1
    DOWN = 2
    BOTH = 3

logger: logging.Logger = bgraph.utils.create_logger(__name__)
"""Logger."""

def check_sections(up : SectionNode, down : SectionNode, dep_type : DependType) -> (bool, SectionNode, SectionNode):
    if dep_type is DependType.UP:
        return True, up, down
    elif dep_type is DependType.DOWN:
        return True, down, up
    else:
        return False, None, None


class SoongFile:

    def __init__(self, path : pathlib.Path = None):
        self.path : pathlib.Path = path
        self.section_nodes : Set[SectionNode] = set()

        self.up_soong_files : Set[SoongFile] = set()
        self.down_soong_files : Set[SoongFile] = set()
        self.child_soong_files : Set[SoongFile] = set()

    def find_section_node(self, name : str) -> Set[SectionNode]:
        result = set()
        for n in self.section_nodes:
            if n.section['section_name'] == name:
                result.add(n)
        return result

    def is_independent_module(self) -> bool:
        for uf in self.up_soong_files:
            if not self.path.parent in list(uf.path.parents):
                return False

        for cf in self.child_soong_files:
            for uf in cf.up_soong_files:
                if not self.path.parent in list(uf.path.parents):
                    return False
        return True

    def get_external_dep_files(self) -> Set[Any]:
        result : Set[SoongFile] = set()
        for uf in self.up_soong_files:
            if not self.path.parent in list(uf.path.parents):
                result.add(uf)

        for cf in self.child_soong_files:
            for uf in cf.up_soong_files:
                if not self.path.parent in list(uf.path.parents):
                    result.add(uf)

        return result

    def name(self) -> str:
        return str(self.path)

    def __key(self):
        return self.name()

    def __hash__(self):
        return hash(self.__key())

    def __eq__(self, other):
        if isinstance(other, SoongFile):
            return self.__key() == other.__key()
        else:
            raise LookupError


class Project:

    def __init__(self, path : pathlib.Path = None):
        self.path : pathlib.Path = path
        self.soong_files : Dict[pathlib.Path, List[SoongFile]] = collections.defaultdict(list)

        self.up_projects : Set[Project] = set()
        self.down_projects : Set[Project] = set()

    def hasSoongFile(self, file_path : pathlib.Path) -> bool:
        return bool(file_path in self.soong_files)

    def name(self) -> str:
        return str(self.path)

    def __key(self):
        return self.name()

    def __hash__(self):
        return hash(self.__key())

    def __eq__(self, other):
        if isinstance(other, Project):
            return self.__key() == other.__key()
        else:
            raise LookupError



def check_node_matching(up : SectionNode,
                        down : SectionNode) -> bool:
    if (up == down or
        up.section['section_type'] in excluded_section_types or
        down.section['section_type'] in excluded_section_types or
        up.section['section_name'] == down.section['section_name']):
        # logger.info("misc unmatch")
        return False
    elif is_defaults_module(up) or is_defaults_module(down):
        # logger.info("default module")
        return False
    elif check_target_matching(up, down) is False:
        # logger.info("target unmatch")
        return False
    elif check_if_cc_bin_unmatching(up, down) is True:
        # logger.info("cc bin unmatch")
        return False
    elif check_host_supported_matching(up, down) is False:
        # logger.info("host unmatch")
        return False
    else:
        return True


class GraphShell(cmd2.Cmd):

    pickle_file : Path = None

    CUSTOM_CATEGORY = 'My Custom Commands'

    def __init__(self):
        super().__init__(
            multiline_commands=['echo'],
            persistent_history_file='.gshell_history.dat',
            startup_script='scripts/startup.txt',
            include_ipy=True,
        )

        self.finished_set : Set[SectionNode] = set()
        self.query_dir_options = ['up', 'down', 'all']
        self.projects: Dict[pathlib.Path, Project] = collections.defaultdict(list)
        self.section_nodes : Set[SectionNode] = set()
        self.named_nodes_dict : Dict[str, Set[SectionNode]] = collections.defaultdict(set)

        # Prints an intro banner once upon application startup
        self.intro = style('Welcome to gshell!', fg=Fg.RED, bg=Bg.WHITE, bold=True)

        # Show this as the prompt when asking for input
        self.prompt = 'gshell> '

        # Used as prompt for multiline commands after the first line
        self.continuation_prompt = '... '

        # Allow access to your application in py and ipy via self
        self.self_in_py = True

        # Set the default category name
        self.default_category = 'cmd2 Built-in Commands'

        # Color to output text in with echo command
        self.foreground_color = Fg.CYAN.name.lower()

        # Make echo_fg settable at runtime
        fg_colors = [c.name.lower() for c in Fg]
        self.add_settable(
            cmd2.Settable('foreground_color', str, 'Foreground color to use with echo command', self, choices=fg_colors)
        )

    def project_provider(self) -> List[str]:
        """A choices provider is useful when the choice list is based on instance data of your application"""
        return [ str(project.path) for project in self.projects.values() ]

    def soong_file_provider(self, arg_tokens: Dict[str, List[str]]) -> List[str]:
        """
        a particular argument expects only 1 token.
        """
        if self.PROJECT in arg_tokens:
            project_path = pathlib.Path(arg_tokens[self.PROJECT][0])
            project = self.projects[project_path]
            return [ str(f.path) for f in project.soong_files.values() ]
        else:
            soong_file_paths = []
            for project in self.projects.values():
                for sf in project.soong_files.values():
                    soong_file_paths.append(str(sf.path))
            return soong_file_paths

    def section_provider(self, arg_tokens: Dict[str, List[str]]) -> List[str]:
        """
        a particular argument expects only 1 token.
        """
        if self.SOONG_FILE in arg_tokens:
            soong_path = pathlib.Path(arg_tokens[self.SOONG_FILE][0])
            for project in self.projects.values():
                for soong_file in project.soong_files.values():
                    if soong_file.path == soong_path:
                        return [ node.section['section_name'] for node in soong_file.section_nodes ]

            return []
        elif self.PROJECT in arg_tokens:
            project = self.projects[Path(arg_tokens[self.PROJECT][0])]
            if isinstance(project, Project):
                return [ node.section['section_name']
                         for soong_file in project.soong_files.values()
                         for node in soong_file.section_nodes ]
            else:
                return []
        else:
            return [ node.section['section_name'] for node in self.section_nodes ]


    @cmd2.with_category(CUSTOM_CATEGORY)
    def do_intro(self, _):
        """Display the intro banner"""
        self.poutput(self.intro)

    @cmd2.with_category(CUSTOM_CATEGORY)
    def do_echo(self, arg):
        """Example of a multiline command"""
        fg_color = Fg[self.foreground_color.upper()]
        self.poutput(style(arg, fg=fg_color))

    DEBUG_SECTION_NAMES = ("libminui", "vts_vndk_utils", "vndk_lib_lists")

    def setup_dependency_by_names(self,
                                  up : SectionNode,
                                  names : List[str],
                                  dep_way : str,
                                  edges : List[Tuple[SectionNode, SectionNode, Dict[str, any]]]):
        for name in names:
            if name and name[0] == ':':
                name = name [1:]
            down_nodes = self.named_nodes_dict.get(name, [])
            for down in down_nodes:
                if (dep_way == 'certificate' and
                    down.section['section_type'] != 'android_app_certificate'):
                    continue
                elif check_node_matching(up, down) or len(down_nodes) == 1:
                    setup_up_down_dependency(up, down, dep_way, edges)
                else:
                    pass
                        # logger.warning("node unmatching! up:%s down:%s", up.name2(), down.name2())

    def generate_edges_from_up(self,
                               up : SectionNode,
                               edges : List[Tuple[SectionNode, SectionNode, Dict[str, any]]]):
        for sub_type, names in up.section.items():
            if sub_type in excluded_sub_types:
                continue

            if isinstance(names, (str, list)):
                logger.info(">> sub_type:%s, names:%s", sub_type, repr(names))
                names = up.section[sub_type] if isinstance(up.section[sub_type], list) else [ up.section[sub_type] ]
                self.setup_dependency_by_names(up, names, sub_type, edges)
            elif isinstance(names, dict):
                result : Dict[Tuple, List[str]] = {}
                sub_types = ("binaries", "static_libs", "shared_libs", "header_libs",
                             "export_shared_lib_headers", "whole_static_libs", "srcs", "tools", "tool_files", "data", "pluginFor")
                for st in sub_types:
                    find_deep_dict(names, (sub_type, ), st, result)
                    for dep_way, names in result.items():
                        dep_way = '#'.join(dep_way)
                        self.setup_dependency_by_names(up, names, dep_way, edges)

        for (down, level) in up.defaults_nodes:
            if level == 0 and down not in up.down_level_nodes:
                setup_up_down_dependency(up, down, 'd_defaults', edges)


    def generate_edges_from_down(self,
                                 down_node : SectionNode,
                                 dep_type : DependType,
                                 edges : List[Tuple[SectionNode, SectionNode, Dict[str, any]]]):
        for up_node in self.section_nodes:
            success, up, down = check_sections(up_node, down_node, dep_type)
            if success:
                success, dep_way = depends_on_impl(up, down)
                if success:
                    edges.append((up, down, {'label' : dep_way}))
                    down.up_level_nodes.add(up)
                    down.up_level_dep_ways[up] = dep_way
                    up.down_level_nodes.add(down)
                    up.down_level_dep_ways[down] = dep_way

        up = down_node
        for (down, level) in up.defaults_nodes:
            if level == 0 and down not in up.down_level_nodes:
                setup_up_down_dependency(up, down, 'd_defaults', edges)


        self.finished_set.add(down_node)


    UNLIMITED_LEVELS : int = 1000000

    DEBUG_SECTION_NAMES = [ "liblpdump_interface", "lpdumpd" ]

    def setup_one_project_and_soong_deps(self,
                                         down_project : Project,
                                         down_soong_file : SoongFile,
                                         down_node : SectionNode):
        for up_node in down_node.up_level_nodes:
            up_project = self.projects[up_node.section['project_path']]
            if not isinstance(up_project, Project):
                raise LookupError

            down_project.up_projects.add(up_project)
            up_project.down_projects.add(down_project)

            up_soong_file = up_project.soong_files[up_node.section['soong_file_path']]
            if not isinstance(up_soong_file, SoongFile):
                raise LookupError

            down_soong_file.up_soong_files.add(up_soong_file)
            up_soong_file.down_soong_files.add(down_soong_file)


    def setup_project_and_soong_files_dep(self):
        for project in self.projects.values():
            for soong in project.soong_files.values():
                self.expand_soong_child(soong)
                for node in soong.section_nodes:
                    self.setup_one_project_and_soong_deps(project, soong, node)

    def build_node_graph(self,
                         max_levels : int,
                         node : SectionNode,
                         edges : List[Tuple[SectionNode, SectionNode, Dict[str, any]]]):
        if max_levels <= 0:
            logger.info("reached end of max_levels %d", max_levels)
        elif node in self.finished_set:
            logger.info("node %s already in finished set", node.name2())
        else:
            logger.info("with node:%s max_levels:%d", node.name2(), max_levels)
            # self.generate_edges_from_down(node, dep_type, edges)
            self.generate_edges_from_up(node, edges)

            # for up_node in node.up_level_nodes.difference(self.finished_set):
            #     self.build_node_graph(max_levels - 1, up_node, dep_type, edges)


    SECTION_NODES_FILE_PATH = "/home/richard/section-nodes.pkl"

    # defaults_set : Set[SectionNode]
    def find_expand_defaults_node(self,
                                  node : SectionNode,
                                  section_name : str,
                                  defaults_set : Set[SectionNode]) -> SectionNode:
        result : Set[SectionNode] = set()
        for n in defaults_set:
            if n.section['section_name'] == section_name:
                if n == node:
                    raise LookupError
                if not node.is_node_in_defaults(n):
                    result.add(n)
                else:
                    logger.info("already merged %s", section_name)
                    return None

        if len(result) == 1:
            return result.pop()
        elif len(result) > 1:
            for n in result:
                if node.section['soong_file_path'] == n.section['soong_file_path']:
                    logger.info("%d more than one, return the one in the same soong!", len(result))
                    return n
                elif node.section['project_path'] == n.section['project_path']:
                    logger.info("%d more than one, return one in the same project!", len(result))
                    return n

            logger.error("can only select first node!")
            return result.pop()
        else:
            logger.error("there is no defaults node with name %s", section_name)
            raise LookupError

    def dump_section(self, info : str, section : Section):
        if info == section['section_name']:
            logger.info("%s %s", info, section['section_name'])
            for key, value in section.items():
                logger.info("key:%s value:%s", key, repr(value))


    def merge_node(self,
                   level : int,
                   owner_node : SectionNode,
                   slave_node : SectionNode,
                   merged_nodes : Set[Tuple[SectionNode, int]]):
        for key, value in slave_node.section.items():
            if key in [ 'section_name', 'section_type', 'project_path', 'soong_file_path', 'project_name' ]:
                pass
            elif key not in owner_node.section:
                if isinstance(value, list):
                    owner_node.section[key] = value.copy()
                else:
                    owner_node.section[key] = value
                    logger.info("merge node:%s new key:%s INTO owner %s", slave_node.section['section_name'], key, owner_node.name2())
            elif not isinstance(owner_node.section[key], type(value)):
                if isinstance(owner_node.section[key], list):
                    owner_node.section[key].append(value)
                elif isinstance(value, list):
                    owner_node.section[key] = [ owner_node.section[key], *value.copy() ]
                    logger.info("after extend value of key %s, %s", key, repr(owner_node.section[key]))
                else:
                    raise LookupError
            elif isinstance(value, list):
                ext_list = [ v for v in value if v not in owner_node.section[key] ]
                if ext_list:
                    logger.info("Extend [%s]: %s with %s, for %s",
                                key, repr(owner_node.section[key]), repr(ext_list), owner_node.name2())
                    owner_node.section[key].extend(ext_list)
                else:
                    logger.info("empty ext_list! key:%s, node:%s, value:[%s] org-value:[%s]",
                                key, owner_node.name2(), repr(value), repr(owner_node.section[key]))
            elif owner_node.section[key] != value:
                logger.info("Overwrite [%s]: %s:%s to %s:%s", key, repr(owner_node.section[key]), type(owner_node.section[key]), repr(value), type(value))
                owner_node.section[key] = value

        merged_nodes.add((slave_node, level))


    def try_expand_defaults(self, node : SectionNode, defaults_set : Set[SectionNode]):
        level = 0
        while 'defaults' in node.section:
            defaults = node.section.pop('defaults')
            logger.info("before expand:%s, DEFAULTS:%s", repr(node.section), repr(defaults))
            if isinstance(defaults, str):
                logger.info("--> %s got a default name: %s", node.name2(), defaults)
                n = self.find_expand_defaults_node(node, defaults, defaults_set)
                if n:
                    logger.info("<< find_expand_defaults_node %s [%s] got [%s]", node.name2(), defaults, n.name2())
                    self.merge_node(level, node, n, node.defaults_nodes)
            elif isinstance(defaults, list):
                for name in defaults:
                    logger.info("%s got a defaults list: %s, name:%s", node.name2(), repr(defaults), name)
                    n = self.find_expand_defaults_node(node, name, defaults_set)
                    if n:
                        self.merge_node(level, node, n, node.defaults_nodes)
            else:
                raise LookupError

            if 'defaults' in node.section:
                defaults = node.section['defaults']
                logger.info("%s after DEFAULTS:%s", node.name2(), repr(defaults))

            level = level + 1

        logger.info("After expand:%s", repr(node.section))

    def expand_default_sections(self, total_nodes : Set[SectionNode]):
        defaults_set = set()
        defaults_types = [t for t in all_module_types if re.search(r"^\w+_defaults\Z", t)]
        logger.info("defaults_types:%s", repr(defaults_types))
        for node in self.section_nodes:
            if node.section['section_type'] in defaults_types:
                defaults_set.add(node)
                logger.info("got a defaults:%s", node.name2())

        # self.check_duplicated_name_sections(defaults_set)

        for n in total_nodes.difference(defaults_set):
            self.try_expand_defaults(n, defaults_set)

    def find_node_with_certificate(self) -> Set[SectionNode]:
        result = set()
        for node in self.section_nodes:
            if 'certificate' in node.section:
                result.add(node)
                logger.info("add node with certificate:%s", node.name2())
        return result

    def find_app_certificate_set(self) -> Set[SectionNode]:
        result = set()
        for node in self.section_nodes:
            if node.section['section_type'] == "android_app_certificate":
                result.add(node)
                logger.info("add a certificate:%s", node.name2())
        return result


    def expand_android_app_certificate_sections(self):
        certificate_node_set = self.find_app_certificate_set()
        for n in self.section_nodes.difference(certificate_node_set):
            self.try_expand_certificate(n, certificate_node_set)

    def try_expand_certificate(self,
                               owner_node : SectionNode,
                               certificate_node_set : Set[SectionNode]):
        while 'certificate' in owner_node.section:
            certificate = owner_node.section['certificate']
            del owner_node.section['certificate']

            logger.info("before expand:%s, CERTIFICATE:%s", repr(owner_node.section), repr(certificate))
            if isinstance(certificate, str):
                logger.info("--> %s got a default name: %s", owner_node.name2(), certificate)
                n = self.find_expand_certificate_node(owner_node, certificate, certificate_node_set)
                if n:
                    # logger.info("<< find_expand_certificate_node %s [%s] got [%s]", owner_node.name2(), certificate, n.name2())
                    self.merge_certificate_node(owner_node, n)
            elif isinstance(certificate, list):
                for name in certificate:
                    # logger.info("%s got a certificate list: %s, name:%s", owner_node.name2(), repr(certificate), name)
                    n = self.find_expand_certificate_node(owner_node, name, certificate_node_set)
                    if n:
                        self.merge_certificate_node(owner_node, n)
            else:
                raise LookupError

            if 'certificate' in owner_node.section:
                certificate = owner_node.section['certificate']
                logger.info("%s after CERTIFICATE:%s", owner_node.name2(), repr(certificate))


        logger.info("After expand:%s", repr(owner_node.section))

    def check_duplicated_name_sections(self, nodes : Set[SectionNode]):
        sections : Dict[str, Set[SectionNode]] = {}
        for node in nodes:
            name = node.section['section_name']
            if not sections.get(name):
                sections[name] = { node }
            elif not isinstance(sections[name], set):
                raise LookupError
            elif node in sections[name]:
                logger.error("node %s already in sections", node.name2())
                raise LookupError
            else:
                sections[name].add(node)

        uniq_cc = 0
        multi_cc = 0
        for name, nodes in sections.items():
            if len(nodes) ==  1:
                uniq_cc = uniq_cc + 1
            else:
                multi_cc = multi_cc + 1
                names = [ n.name2() for n in nodes ]
                logger.info("[%s]:", name)
                for s in names:
                    logger.info("\t[%s]", s)                    
                logger.info("\n")
                
        logger.info("got uniq:%d, multi:%d", uniq_cc, multi_cc)

        
    def do_check_duplicated_name_sections(self, _ : argparse.Namespace):
        self.check_duplicated_name_sections(self.section_nodes)


    def do_find_overlapped_certificate(self, _ : argparse.Namespace):
        certificate_node_set = self.find_app_certificate_set()
        i = 0
        total = 0
        for node in certificate_node_set:
            if 'certificate' in node.section:
                logger.info("%d:%d cert node %s contains another cert %s",
                            i, total, node.name2(), repr(node.section['certificate']))
                self.deep_dump_dict(node.section, 0, "dump app cert node")
                i = i + 1
            total = total + 1

    def do_find_node_with_certificate(self, _ : argparse.Namespace):
        nodes_with_cert = self.find_node_with_certificate()
        i = 0
        total = 0
        for node in nodes_with_cert:
            cert = node.section['certificate']
            if isinstance(cert, str):
                if re.search(r"^:", cert):
                    pass
                else:
                    logger.info(f"{i}/{total} node [%s] with cert:[%s]", node.name2(), node.section['certificate'])
                    i = i + 1
            else:
                raise LookupError
            total = total + 1

    def find_node_with_backend(self) -> Set[SectionNode]:
        result = set()
        for node in self.section_nodes:
            if has_backend_dict(node.section):
                result.add(node)
        return result

    def do_find_node_with_backend(self, _ : argparse.Namespace):
        nodes_with_backend = self.find_node_with_backend()
        i = 0
        for node in nodes_with_backend:
            logger.info(f"{i} node [%s] with backend:[%s]", node.name2(), node.section['backend'])
            self.deep_dump_dict(node.section['backend'], 1, "dump the backend")
            i = i + 1

    query_parser = Cmd2ArgumentParser(description="query section deps of a soong file of a project, with direct")

    @with_argparser(query_parser)
    def do_expand_sections(self, args : argparse.Namespace):
        total_nodes = self.section_nodes
        if args.section:
            total_nodes = self.find_section_node(args.project, args.soong_file, args.section)
        self.expand_default_sections(total_nodes)


    def expand_soong_child(self, sfile : SoongFile):
        root = Path(".")
        path = sfile.path.parent
        # logger.info("path:%s, root:%s", repr(path), repr(root))
        while path != root:
            # logger.info("-- path:%s, root:%s", repr(path), repr(root))
            soong_path = path.parent / 'Android.bp'
            if soong_path.exists():
                sf = self.find_soong_file(soong_path)
                if sf:
                    sf.child_soong_files.add(sfile)

            path = path.parent

    def expand_all_soong_up_files(self):
        for project in self.projects.values():
            for sf in project.soong_files.values():
                self.expand_soong_child(sf)


    @with_argparser(query_parser)
    def do_gen_nodes_graph(self, args : argparse.Namespace):
        self.finished_set.clear()

        total_nodes : Set[SectionNode] = self.section_nodes
        if args.project or args.soong_file or args.section:
            total_nodes = self.find_section_node(args.project, args.soong_file, args.section)

        for n in total_nodes:
            edges : List[Tuple[SectionNode, SectionNode, Dict[any]]] = []
            self.build_node_graph(self.UNLIMITED_LEVELS, n, edges)

        self.setup_project_and_soong_files_dep()

        # try:
        #     with open(self.SECTION_NODES_FILE_PATH, "wb") as file:
        #         pickle.dump(self.section_nodes, file)
        # except pickle.PickleError:
        #     logger.error("Failed to pickle dump section nodes to file %s", self.SECTION_NODES_FILE_PATH)

    def load_nodes_graph(self):
        with open(self.SECTION_NODES_FILE_PATH, "rb") as file:
            section_nodes = pickle.load(file)
            self.init_section_nodes(section_nodes)

    def do_load_nodes_graph(self, _ : argparse.Namespace):
        self.load_nodes_graph()

    dump_parser = Cmd2ArgumentParser(description="dump section nodes")
    dump_parser.add_argument('-l', '--max_levels', type=int, default=1, help='1 means only dump the leaf node')
    dump_parser.add_argument('-m', '--modules_file', type=str, default="modules.conf", help='dump android.bp path into module files')
    dump_parser.add_argument('-M', '--single_module', type=str, default=None, help='a module path or backup module path')
    dump_parser.add_argument('-s', '--success_modules_file', type=str, default="success-modules.conf", help='dump android.bp path into module files')
    dump_parser.add_argument('-f', '--failed_modules_file', type=str, default="failed-modules.conf", help='dump android.bp path into module files')
    dump_parser.add_argument('-a', '--all', action='store_true', help='dump all nodes')
    dump_parser.add_argument('-k', '--keep_going', action='store_true', default=False, help='dump all nodes')
    dump_parser.add_argument('-V', '--verbose', action='store_true', help='for validate soong file command')
    dump_parser.add_argument('--soong_file', choices_provider=soong_file_provider, metavar="SOONG", help="tab complete using a choices_provider")

    def dump_types_provider(self) -> List[str]:
        return [ self.PROJECT, self.SOONG_FILE, self.SECTION, self.CHECK_CIRCULAR_DEP, self.ALL_MODULE_TYPES ]

    dump_parser.add_argument(
        "--type",
        choices_provider=dump_types_provider,
        metavar="TYPE",
        help="dump node types"
    )


    def dump_module_types_provider(self) -> List[str]:
        return all_module_types

    dump_parser.add_argument(
        "--module_type",
        choices_provider=dump_module_types_provider,
        metavar="MODTYPE",
        help="dump node with specified module type"
    )

    def dump_up_node_graph(self,
                           root : SectionNode,
                           levels : int,
                           max_levels : int) -> None:
        if levels < max_levels:
            if levels == 0:
                logger.info("root-up-node: %s", root.name2())

            tab = '--'
            levels = levels + 1
            for node in root.up_level_nodes:
                logger.info("%d %s: %s", levels, ''.join([c * levels for c in tab]), node.name2())
                self.dump_up_node_graph(node, levels, max_levels)

    def dump_down_node_graph(self,
                             root : SectionNode,
                             levels : int,
                             max_levels : int) -> None:
        if levels < max_levels:
            if levels == 0:
                logger.info("root-node: %s", root.name2())

            tab = '--'
            levels = levels + 1
            for node in root.down_level_nodes:
                logger.info("%d %s: %s", levels, ''.join([c * levels for c in tab]), node.name2())
                self.dump_down_node_graph(node, levels, max_levels)

    def dump_up_levels_node(self,
                            root : SectionNode,
                            levels : int,
                            max_up_levels : int) -> None:
        if levels < max_up_levels:
            tab = '^'
            levels = levels + 1
            for node in root.up_level_nodes:
                logger.info("%d %s: %s %s",
                            levels, ''.join([c * levels for c in tab]), node.name2(), root.up_level_dep_ways[node])
                self.dump_up_levels_node(node, levels, max_up_levels)

    def dump_down_levels_node(self,
                              root : SectionNode,
                              levels : int,
                              max_down_levels : int) -> None:
        if levels < max_down_levels:
            tab = 'v'
            levels = levels + 1
            for node in root.down_level_nodes:
                logger.info("%d %s: %s %s",
                            levels, ''.join([c * levels for c in tab]), node.name2(), root.down_level_dep_ways[node])
                self.dump_down_levels_node(node, levels, max_down_levels)

    def deep_dump_dict(self, data : Dict, levels : int, hint : str):
        if levels == 0:
            logger.info("%s", hint)

        tab = '\t'
        for key, value in data.items():
            logger.info("%skey:%s val-[%s]:%s",
                        ''.join([c * (levels + 1) for c in tab]), key, type(value), repr(value))
            if isinstance(value, dict):
                self.deep_dump_dict(value, levels + 1, None)
                


    def dump_both_levels_node(self,
                              root : SectionNode,
                              levels : int,
                              max_up_levels : int,
                              max_down_levels : int) -> None:
        logger.info("root-node: %s", root.name2())
        self.deep_dump_dict(root.section, 0, "root-node-dict")
        self.dump_up_levels_node(root, levels, max_up_levels)
        self.dump_down_levels_node(root, levels, max_down_levels)


    def check_if_circular_depended(self,
                                   node : SectionNode,
                                   down_node : SectionNode,
                                   checked_path : List[Tuple[SectionNode, str]],
                                   circular_nodes : Set[SectionNode],
                                   uncircular_nodes : Set[SectionNode]) -> bool:
        if node in circular_nodes:
            logger.info("=== Old Circular Node:%s", node.name2())
            return True
        elif node in uncircular_nodes:
            return False
        elif node in [ n for (n, _) in checked_path ]:
            logger.info("\n")
            for (n, dep_way) in checked_path:
                logger.info("In List:%s, dep:%s", n.name2(), dep_way)
            if down_node:
                logger.info("=== Target Circular Node:%s dep-way:%s", node.name2(), down_node.up_level_dep_ways[node])
            else:
                logger.info("=== Target Circular Node:%s dep-way:None", node.name2())
            circular_nodes.add(node)
            return True
        else:
            if not down_node:
                checked_path.append((node, "ROOT"))
            else:
                checked_path.append((node, down_node.up_level_dep_ways[node]))

            for n in node.up_level_nodes:
                if self.check_if_circular_depended(n, node, checked_path.copy(), circular_nodes, uncircular_nodes):
                    return True
                else:
                    uncircular_nodes.add(n)

            return False

    def check_if_any_circular_depended(self, nodes : Set[SectionNode]):
        circular_nodes = set()
        uncircular_nodes = set()
        for i, n in enumerate(nodes):
            if self.check_if_circular_depended(n, None, [], circular_nodes, uncircular_nodes):
                logger.info("%d got a circular dep node %s", i, n.name2())
            else:
                logger.info("%d got a normal dep node %s", i, n.name2())

        logger.info("there are %d circular dep nodes in these %d nodes", len(circular_nodes), len(nodes))

        for i, node in enumerate(circular_nodes):
            logger.info("%d circular node %s", i, node.name2())
            

    def dump_project_graph(self, project : Project, levels : int, max_levels : int) -> None:
        if levels < max_levels:
            if levels == 0:
                logger.info("root-project: %s", project.name())

            tab = '    '
            levels = levels + 1
            for down_pj in project.down_projects:
                logger.info("%d %s |---: %s", levels, ''.join([c * levels for c in tab]), down_pj.name())
                self.dump_project_graph(down_pj, levels, max_levels)

    def dump_soong_file(self, file : SoongFile, verbose : bool):
        ext_dep_files = file.get_external_dep_files()
        logger.info("dump soong file [%s], num of external deps:%d, num of nodes %d, num of up files %d, num of down files %d, num of children %d",
                    file.name(), len(ext_dep_files),
                    len(file.section_nodes), len(file.up_soong_files), len(file.down_soong_files), len(file.child_soong_files))

        logger.info("==== section nodes %d", len(file.section_nodes))
        for i, node in enumerate(file.section_nodes):
            logger.info("\t%d node %s, up nodes %d, down nodes %d",
                        i, node.name2(), len(node.up_level_nodes), len(node.down_level_nodes))

        if verbose is True:
            logger.info("---- down files %d", len(file.down_soong_files))
            for i, down_file in enumerate(file.down_soong_files):
                logger.info("\t%d down file %s, up files %d, down files %d",
                            i, down_file.name(), len(down_file.up_soong_files), len(down_file.down_soong_files))

        if verbose is True:
            logger.info("++++ up files %d", len(file.up_soong_files))
            for i, up_file in enumerate(file.up_soong_files):
                logger.info("\t%d up file %s, up files %d, down files %d",
                            i, up_file.name(), len(up_file.up_soong_files), len(up_file.down_soong_files))

        if verbose is True:
            logger.info("~~~~ child files %d", len(file.child_soong_files))
            for i, child in enumerate(file.child_soong_files):
                logger.info("\t%d child file %s, up files %d, down files %d",
                            i, child.name(), len(child.up_soong_files), len(child.down_soong_files))

        if verbose is True:
            logger.info("==== ext dep files %d", len(ext_dep_files))
            for i, ext_file in enumerate(ext_dep_files):
                logger.info("\t%d external file %s, up files %d, down files %d",
                            i, ext_file.name(), len(ext_file.up_soong_files), len(ext_file.down_soong_files))


    def dump_soong_file_with_level(self,
                                   levels : int,
                                   max_levels : int,
                                   undumped_files : Set[SoongFile],
                                   dumped_files : Set[SoongFile],
                                   modules_file : IO[Any]) -> None:
        if levels < max_levels:
            if not undumped_files:
                logger.info("REACHED THE END WITH FILE LEVELS %d", levels)
            else:
                tab = '--'
                once_dumped_files : Set[SoongFile] = set()
                for file in undumped_files:
                    logger.info("handle soong %s, up_soong_files:%d dumped_files:%d, undumped_files:%d",
                                file.path, len(file.up_soong_files), len(dumped_files), len(undumped_files))
                    valid_up_files = file.get_external_dep_files()
                    if (not valid_up_files or file.is_independent_module()):
                        once_dumped_files.add(file)
                        modules_file.write("%s\n" % str(file.path.absolute()))
                        # backup_module(file.path.absolute())
                        dumped_cc = len(dumped_files) + len(once_dumped_files)
                        logger.info("levels:%d dumped:%d %s:%s",
                                    levels, dumped_cc, ''.join([c * levels for c in tab]), file.name())
                        for i, node in enumerate(file.section_nodes):
                            logger.info("%d%s:%s", i, ''.join([c * (levels + 2) for c in tab]), node.name2())

                dumped_files.update(once_dumped_files)
                undumped_files = undumped_files.difference(dumped_files)
                self.dump_soong_file_with_level(levels + 1, max_levels, undumped_files, dumped_files, modules_file)
        else:
            logger.info("REACHED THE MAX FILE LEVEL %d %d", levels, max_levels)

    def dump_project_graph_with_level(self,
                                      levels : int,
                                      max_levels : int,
                                      undumped_projects : Set[Project],
                                      dumped_projects : Set[Project]) -> None:
        if levels < max_levels:
            if not undumped_projects:
                logger.info("REACHED THE END WITH PROJECT LEVELS %d", levels)
            else:
                tab = '--'
                once_dumped_projects : Set[Project] = set()
                for project in undumped_projects:
                    valid_up_projects = project.up_projects.difference(dumped_projects)
                    if not valid_up_projects:
                        once_dumped_projects.add(project)
                        dumped_cc = len(dumped_projects) + len(once_dumped_projects)
                        logger.info("levels:%d dumped:%d %s:%s",
                                    levels, dumped_cc, ''.join([c * levels for c in tab]), project.name())
                    for file in project.soong_files.values():
                        logger.info("%s:%s", ''.join([c * (levels + 2) for c in tab]), file.name())
                        for node in file.section_nodes:
                            logger.info("%s:%s", ''.join([c * (levels + 4) for c in tab]), node.name2())

                dumped_projects.update(once_dumped_projects)
                undumped_projects = undumped_projects.difference(dumped_projects)
                self.dump_project_graph_with_level(levels + 1, max_levels, undumped_projects, dumped_projects)
        else:
            logger.info("REACHED THE MAX PROJECT LEVEL %d %d", levels, max_levels)

    def dump_soong_file_graph(self, soong_file : SoongFile, levels : int, max_levels : int) -> None:
        if levels < max_levels:
            if levels == 0:
                logger.info("root-soong: %s", soong_file.name())
            tab = '    '
            levels = levels + 1
            for down_soong in soong_file.down_soong_files:
                logger.info("%d %s |---: %s", levels, ''.join([c * levels for c in tab]), down_soong.name())
                self.dump_soong_file_graph(down_soong, levels, max_levels)


    def dump_node_graph_with_level(self,
                                   levels : int,
                                   max_levels : int,
                                   undumped_nodes : Set[SectionNode],
                                   dumped_nodes : Set[SectionNode]) -> None:
        if levels < max_levels:
            if not undumped_nodes:
                logger.info("REACHED THE END WITH LEVELS %d", levels)
            else:
                tab = '--'
                once_dumped_nodes : Set[SectionNode] = set()
                for node in undumped_nodes:
                    valid_up_level_nodes = node.up_level_nodes.difference(dumped_nodes)
                    if not valid_up_level_nodes:
                        once_dumped_nodes.add(node)
                        dumped_cc = len(dumped_nodes) + len(once_dumped_nodes)
                        logger.info("levels:%d dumped:%d %s:%s", levels, dumped_cc, ''.join([c * levels for c in tab]), node.name2())
                dumped_nodes.update(once_dumped_nodes)
                undumped_nodes = undumped_nodes.difference(dumped_nodes)
                self.dump_node_graph_with_level(levels + 1, max_levels, undumped_nodes, dumped_nodes)
        else:
            logger.info("REACHED THE MAX LEVEL %d %d", levels, max_levels)

    def dump_all_module_types(self):
        module_types : Dict[str, int] = {}
        for node in self.section_nodes:
            st = node.section['section_type']
            if st in module_types:
                module_types[st] = module_types[st] + 1
            else:
                module_types[st] = 1

        index = 0
        module_types = dict(sorted(module_types.items(), key=lambda x:x[1]))
        with open("/home/richard/all-module-types.txt", "w") as file:
            file.write("[ ")
            for key, val in module_types.items():
                logger.info("%d type: [%s, %d]", index, key, val)
                index = index + 1
                file.write("\"%s\", " % key)
            file.write(" ]")


    def diagnostic(self, soong_file_path : str, up_section_name : str, down_section_name : str):
        logger.error("MODULE:%s  UP-NODE:%s  DOWN-NODE:%s", soong_file_path, up_section_name, down_section_name)

        soong_file : SoongFile = self.find_soong_file(Path(soong_file_path))
        if not soong_file:
            logger.error("NO SOONG FILE:%s", soong_file_path)
            return

        up_nodes = soong_file.find_section_node(up_section_name)
        down_nodes = self.find_section_node(None, None, down_section_name)

        for i, up in enumerate(up_nodes):
            self.deep_dump_dict(up.section, 0, f"{i} up node:{up.name2()}")

        for i, down in enumerate(down_nodes):
            self.deep_dump_dict(down.section, 0, f"{i} down node:{down.name2()}")


    def compile_aosp(self) -> bool:
        import os
        import pprint
        import shlex
        import subprocess

        command = shlex.split("env -i bash -c 'source build/envsetup.sh && m'")
        with subprocess.Popen(command, stdout = subprocess.PIPE) as proc:
            result : bool = False
            for line in proc.stdout:
                if isinstance(line, bytes):
                    line = line.decode('utf-8')
                line = line.strip()

                match = re.match(r'^error: (\w+.*Android.bp):\d+:\d+: "(\w+.*)" .* on undefined module "(\w+.*)"\Z', line)
                if match:
                    self.diagnostic(*match.groups())

                if re.search(r'error|fail|unknown', line):
                    logger.error("%s", line)

                if line.find("soong bootstrap failed with:") != -1:
                    result = False
                elif line.find("build completed successfully") != -1:
                    result = True
            proc.communicate()

            if result is True:
                logger.info("================ COMPILED AOSP OK ================")

            return result


    @with_argparser(dump_parser)
    def do_compile_aosp(self, args : argparse.Namespace):
        self.compile_aosp()

    def write_line_to(self, log_file_path : str, mode : str, line : str):
        with open(log_file_path, mode, encoding='utf-8') as file:
            file.write("%s\n" % line)

    @with_argparser(dump_parser)
    def do_auto_backup(self, args : argparse.Namespace):
        with open(args.modules_file, 'r', encoding='utf-8') as modules_file:
            paths = [ Path(line.strip()) for line in modules_file.readlines() if line.strip() and not re.search(r"^#", line) ]
            if not paths:
                logger.error("no valid module path!")
            for path in paths:
                if path.exists():
                    logger.info(">> backup module %s", path)
                    backup_path = backup_module(path)
                    if self.compile_aosp():
                        logger.info("SUCCESS PATH:%s", path)
                        self.write_line_to(args.success_modules_file, 'a', path)
                    else:
                        logger.info("FAILED PATH:%s", path)
                        self.write_line_to(args.failed_modules_file, 'a', path)
                        restore_module(backup_path)
                        if not args.keep_going:
                            logger.info("not keep going, ended with module:%s", path)
                            return
                else:
                    logger.info(">> path %s not exist!", path)

    @with_argparser(dump_parser)
    def do_backup(self, args : argparse.Namespace):
        if args.single_module:
            path = Path(args.single_module)
            if path.exists():
                logger.info("backup single module path %s", path)
                backup_module(path)
            else:
                logger.error("non-exist single module path %s", path)
        else:
            with open(args.modules_file, "r", encoding='utf-8') as modules_file:
                paths = [ Path(line.strip())
                          for line in modules_file.readlines() if line.strip() and not re.search(r"^#", line) ]
                if not paths:
                    logger.error("no valid module path!")
                    return

                for path in paths:
                    if path.exists():
                        logger.info(">> backup module %s", path)
                        backup_module(path)
                    else:
                        logger.info(">> path %s not exist!", path)

    @with_argparser(dump_parser)
    def do_restore(self, args : argparse.Namespace):
        if args.single_module:
            path = Path(args.single_module)
            if is_backup_module_path(path):
                logger.info("restore single module path %s", path)
                restore_module(path)
            elif is_normal_module_path(path):
                (success, backup_path) = conv_to_backup_path(path)
                if success:
                    logger.info(">> restore single module path %s", backup_path)
                    restore_module(backup_path)
                else:
                    logger.error("invalid input path %s, it normal path but can not conv to backup path", path)
            else:
                logger.error("invalid input path %s, it's neither normal nor backup path", path)
        else:
            with open(args.modules_file, "r", encoding='utf-8') as modules_file:
                backup_paths = [ gen_backup_path(Path(line.strip()))
                                 for line in modules_file.readlines() if line.strip() and not re.search(r"^#", line) ]
                if not backup_paths:
                    logger.error("no valid module backup path!")
                for path in backup_paths:
                    if path.exists():
                        logger.info(">> restore module %s", path)
                        restore_module(path)
                    else:
                        logger.info(">> path %s not exist!", path)


    def sort_modules_file(self, path : str):
        lines = []
        with open(path, 'r', encoding='utf-8') as file:
            lines = sorted([line.strip() for line in file.readlines() if line.strip() and not re.search(r"^#", line)],
                           key=lambda x: tuple(natsort_key(s) for s in Path(x).parts))

        if lines:
            with open(path, 'w', encoding='utf-8') as file:
                for line in lines:
                    file.write(f"{line}\n")


    @with_argparser(dump_parser)
    def do_dump(self, args : argparse.Namespace):
        total_nodes = set()
        if not args.module_type:
            total_nodes = self.section_nodes
        else:
            for node in self.section_nodes:
                if node.section['section_type'] == args.module_type:
                    total_nodes.add(node)
                    logger.info("%d added node:[%s] with type:[%s] into total set", len(total_nodes), node.name2(), args.module_type)

        if args.type == self.ALL_MODULE_TYPES:
            self.dump_all_module_types()
        elif args.type == self.CHECK_CIRCULAR_DEP:
            self.check_if_any_circular_depended(total_nodes)
        elif args.type == self.SECTION:
            if args.all:
                self.dump_node_graph_with_level(0, args.max_levels, total_nodes, set())
            else:
                for node in total_nodes:
                    if not node.up_level_nodes: # start from leaf node
                        self.dump_down_node_graph(node, 0, args.max_levels)
        elif args.type == self.PROJECT:
            logger.info("dump project")
            if args.all:
                total_projects = set()
                for project in self.projects.values():
                    total_projects.add(project)
                logger.info("num of total projects:%d", len(total_projects))
                self.dump_project_graph_with_level(0, args.max_levels, total_projects, set())
            else:
                for project in self.projects.values():
                    if not project.up_projects:
                        self.dump_project_graph(project, 0, args.max_levels)
        elif args.type == self.SOONG_FILE:
            logger.info("dump soong file")
            total_files = set()
            with open(args.modules_file, 'w', encoding='utf-8') as modules_file:
                path = Path(args.soong_file) if args.soong_file else None
                for project in self.projects.values():
                    for file in project.soong_files.values():
                        if path is None or file.path == path:
                            total_files.add(file)
                            logger.info("added file %s", file.path)

                if len(total_files) == 1:
                    self.dump_soong_file(total_files.pop(), args.verbose)
                else:
                    self.dump_soong_file_with_level(0, args.max_levels, total_files, set(), modules_file)
                    self.sort_modules_file(args.modules_file)

        else:
            raise LookupError("invalid args type")


    def gen_section_up_graph(self, down_node : SectionNode, max_levels : int):
        graph = nx.DiGraph()
        # graph = nx.complete_graph(3, create_using=nx.DiGraph)
        # graph = nx.balanced_tree(r=5, h=6, create_using=nx.DiGraph)

        self.finished_set.clear()
        edges : List[Tuple[SectionNode, SectionNode, Dict[str, any]]] = []

        self.build_node_graph(max_levels, down_node, edges)

        graph.add_node(down_node, label=down_node.name())

        for up_node, down_node, label in edges:
            graph.add_node(up_node, label=up_node.name())
            # graph.add_node(up_node, label=getSectionKey(up_node.section))
            # graph.add_node(down_node, label=getSectionKey(down_node.section))

        graph.add_edges_from(edges)


        logger.info(">> graphviz_layout")
        # pos = graphviz_layout(graph, prog="twopi")
        pos = graphviz_layout(graph, prog="neato")
        # pos = graphviz_layout(graph, prog="dot")
        # pos = graphviz_layout(graph, prog="circo")
        logger.info(">> draw")
        # nx.draw_networkx_edge_labels(graph, pos)

        nx.draw_networkx_nodes(graph, pos, node_size=50, node_color='g', alpha = 0.1)  # draws nodes
        nx.draw_networkx_edges(graph, pos, width=2.0, edge_color='r', alpha = 0.6)  # draws edges
        nx.draw_networkx_edge_labels(graph, pos, edge_labels=nx.get_edge_attributes(graph, 'label')) # edge lables
        nx.draw_networkx_labels(graph, pos, labels=nx.get_node_attributes(graph, 'label')) # node lables

        # nx.draw(graph, pos, node_size=50, with_labels=True)

        logger.info("%s", f">> save {down_node.section['section_name']}.png")
        plt.savefig(f'{down_node.section["section_name"]}.png') # save as png
        plt.box(False) # no frame around it
        plt.show() # display

        logger.info("%s", f">> write_network_text {down_node.section['section_name']}.nwk")
        # nx.write_network_text(graph, path=f'{section["section_name"]}.nwk', with_labels='label', max_depth=20, ascii_only=True, sources = [ getSectionKey(section) ])
        nx.write_network_text(graph, path=f'{down_node.section["section_name"]}.nwk', with_labels=True, ascii_only=True)

    def init_section_nodes(self, sections : Sequence[Section]) -> None:

        self.projects.clear()
        self.section_nodes.clear()

        for section in sections:
            if has_invalid_target_arch(section):
                logger.info("ignore section with invalid target:%s section:%s", section['target_arch'], getSectionKey(section))
            else:
                self.section_nodes.add(SectionNode(section))

        for node in self.section_nodes:
            self.named_nodes_dict[node.section['section_name']].add(node)
            for name in get_backend_suffixed_names(node.section):
                self.named_nodes_dict[name].add(node)

        for node in self.section_nodes:
            project_path = node.section['project_path']
            soong_file_path = node.section['soong_file_path']
            if not isinstance(project_path, pathlib.Path) or not isinstance(soong_file_path, pathlib.Path):
                logger.info("project or soong is not a path")
            else:
                project = self.projects[project_path]
                if not isinstance(project, Project): # no project
                    project = Project(project_path)
                    self.projects[project_path] = project

                soong_file = project.soong_files[soong_file_path]
                if not isinstance(soong_file, SoongFile): # no soong file
                    soong_file = SoongFile(soong_file_path)
                    project.soong_files[soong_file_path] = soong_file

                if not node in soong_file.section_nodes: # no section
                    soong_file.section_nodes.add(node)

        for project_path, project in self.projects.items():
            logger.info("\t project:%s", project.path)
            for soong_file in project.soong_files.values():
                logger.info("\t\t soong file:%s", soong_file.path)
                for node in soong_file.section_nodes:
                    logger.info("\t\t\t section:%s/%s", node.section['section_name'], node.section['section_type'])

        self.expand_default_sections(self.section_nodes)

        logger.info("TOTALLY THERE ARE %d PROJECTS, %d SOONG FILES, %d SECTION NODES",
                    len(self.projects), sum(len(proj.soong_files.values()) for proj in self.projects.values()), len(self.section_nodes))

    def dir_provider(self) -> List[str]:
        """A choices provider is useful when the choice list is based on instance data of your application"""
        return self.query_dir_options

    # Parser for example command

    # # Tab complete from choices provided by a choices_provider
    # query_parser.add_argument(
    #     "direct",
    #     choices_provider=dir_provider,
    #     metavar="DIR",
    #     help="tab complete using a choices_provider"
    # )

    PROJECT : str = "project"
    SOONG_FILE : str = "soong_file"
    SECTION : str = "section"
    NODE : str = "node"
    ALL_MODULE_TYPES : str = "all_module_types"
    CHECK_CIRCULAR_DEP : str = "check_circular_dep"

    """Type of the section (e.g. cc_library)."""

    query_parser.add_argument('-u', '--up',
                              action='store_true',
                              help='list who depends on the specified scopes including project, Android.bp and target')
    query_parser.add_argument('-d', '--down',
                              action='store_true',
                              help='list targets on which the specified module depends')
    query_parser.add_argument('-a', '--all',
                              action='store_true',
                              help='list all dependencies including both the up and down')

    query_parser.add_argument(
        f"--{PROJECT}",
        choices_provider=project_provider,
        metavar="PROJECT",
        help="tab complete using a choices_provider"
    )

    query_parser.add_argument(
        f"--{SOONG_FILE}",
        choices_provider=soong_file_provider,
        metavar="SOONG",
        help="tab complete using a choices_provider"
    )

    query_parser.add_argument(
        f"--{SECTION}",
        choices_provider=section_provider,
        metavar="SECTION",
        help="specify the section with a name"
    )

    query_parser.add_argument('-l', '--max_levels', type=int, default=2, help='output [n] times')

    def find_soong_file(self, soong_path : Path) -> SoongFile:
        for project in self.projects.values():
            if soong_path in project.soong_files:
                return project.soong_files[soong_path]
        return None

    def find_section_node(self, project_path : str, soong_file_path : str, section_name : str) -> Set[SectionNode]:
        result : Set[SectionNode] = set()
        if soong_file_path:
            soong_file = self.find_soong_file(Path(soong_file_path))
            if isinstance(soong_file, SoongFile):
                for node in soong_file.section_nodes:
                    if (not section_name or node.section["section_name"] == section_name):
                        result.add(node)
        elif project_path:
            project = self.projects[project_path]
            if isinstance(project, Project):
                for sf in project.soong_files:
                    for node in sf.section_nodes:
                        if (not section_name or node.section["section_name"] == section_name):
                            result.add(node)
        else:
            for node in self.section_nodes:
                if (not section_name or node.section["section_name"] == section_name):
                    result.add(node)

        return result


    query_parser.add_argument('-V', '--verbose', action='store_true', help='for validate soong file command')
    query_parser.add_argument('-G', '--gen_graph', action='store_true', help='for validate soong file command')

    @with_argparser(query_parser)
    def do_validate_soong_file(self, args : argparse.Namespace):
        if args.soong_file:
            soong : SoongFile = self.find_soong_file(Path(args.soong_file))
            if not soong:
                logger.error("invalid soong file %s", args.soong_file)
            else:
                total_nodes = self.find_section_node(None, args.soong_file, None)
                logger.info("find %d of total nodes", len(total_nodes))
                if args.gen_graph:
                    for n in total_nodes:
                        edges : List[Tuple[SectionNode, SectionNode, Dict[any]]] = []
                        self.build_node_graph(self.UNLIMITED_LEVELS, n, edges)

                logger.info("dump all soong file upers %d", len(soong.up_soong_files))
                for i, sf in enumerate(soong.up_soong_files):
                    logger.info("%d up soong file:%s", i, sf.name())
                    for i, node in enumerate(sf.section_nodes):
                        logger.info("%s has node [%d]:%s", sf.name(), i, node.name2())
                        if args.verbose:
                            self.dump_both_levels_node(node, 0, args.max_levels, args.max_levels)


    @with_argparser(query_parser)
    def do_query(self, args: argparse.Namespace):
        """Repeats what you tell me to."""
        logger.info("got project:%s soong:%s section:%s", args.project, args.soong_file, args.section)
        nodes : Set[SectionNode] = self.find_section_node(args.project, args.soong_file, args.section)
        if not nodes:
            logger.error("find no section node!")
        else:
            for i, node in enumerate(nodes):
                logger.info(">> dump_both_levels_node [%d]:%s", i, node.name2())
                self.dump_both_levels_node(node, 0, args.max_levels, args.max_levels)

        # logger.info("gen_section_up_graph:[%s] max_levels:%d", node.name2(), args.max_levels)
        # for n in node.up_level_nodes:
        #     logger.info("---- up %s", n.name2())
        # for n in node.down_level_nodes:
        #     logger.info("---- down %s", n.name2())
        # self.gen_section_up_graph(node, args.max_levels)


    argparser = Cmd2ArgumentParser()
    argparser.add_argument('-p', '--piglatin', action='store_true', help='atinLay')
    argparser.add_argument('-s', '--shout', action='store_true', help='N00B EMULATION MODE')
    argparser.add_argument('-r', '--repeat', type=int, help='output [n] times')
    # argparser.add_argument('word', nargs='?', help='word to say')

    @with_argparser(argparser)
    def do_speak(self, opts):
        """Repeats what you tell me to."""
        arg = opts.word
        if opts.piglatin:
            arg = '%s%say' % (arg[1:], arg[0])
        if opts.shout:
            arg = arg.upper()
        repetitions = opts.repeat or 1
        for i in range(min(repetitions, 20)):
            self.poutput(arg)

    def set_pick_file(self, pickle_file : Path):
        self.pickle_file = pickle_file

    def do_exit(self, inp):
        print("Bye")
        return True

    def help_exit(self):
        print("exit the application. Shorthand: x q Ctrl-D.'")

    def do_add(self, inp):
        print(f"adding '{inp}'")

    def help_add(self):
        print("Add a new entry to the system.")

    def default(self, line):
        if line == 'x' or line == 'q':
            return self.do_exit(line)
 
        print("Default: {}".format(line))
 
    do_EOF = do_exit
    help_EOF = help_exit

app = typer.Typer()

@app.command(name="generate-single")
def generate_single(
    result_dir: Path = typer.Argument(
        ...,
        help="Where to store the result",
        dir_okay=True,
        exists=True,
        writable=True,
        resolve_path=True,
    ),
    branch_name: str = typer.Argument(
        ..., help="Branch from which generating the BGraph"
    ),
    mirror: str = typer.Argument(
        ...,
        help="Mirror directory for AOSP (either a link or a path)",
    ),
    workdir: Optional[Path] = typer.Option(
        None, help="Workdir", dir_okay=True, writable=True, exists=True
    ),
):
    """Generate a BGraph from a branch.

    It will work in the workdir and store results in result_dir.
    """

    # Assume the mirror is a Path if "http" is not found in mirror.
    mirror_path: Union[str, pathlib.Path] = bgraph.utils.clean_mirror_path(mirror)

    workdir = bgraph.builder.compose_local_manifest_branch(mirror_path, workdir)

    if workdir is None:
        typer.echo("Compose manifest failed.", err=True)
        raise typer.Exit(code=1)

    bgraph.builder.convert(workdir, result_dir)

gshell = GraphShell()

@app.command(name="load-pickle")
def load_pickle(
    file_path: Path = typer.Argument(
        ...,
        help="Where to load the pickle file",
        exists=True,
    ),
):
    """test load pickle file soong parser from a pickle file.
    """

    print("file_path is " + repr(file_path))

    with open(file_path, "rb") as file:
        soong_parser = pickle.load(file)

    print("sections len ", len(soong_parser.sections))
    print("section_nodes len ", len(soong_parser.section_nodes))

    # for section in soong_parser.section_nodes:
    #     print("\nsection: " + getSectionKey(section))
    #     for key in section:
    #         print(key + ":" + repr(section[key]))

    import sys
    gshell.init_section_nodes(soong_parser.sections.values())
    sys.exit(gshell.cmdloop())


@app.command()
def generate(
    result_dir: Path = typer.Argument(
        ...,
        dir_okay=True,
        exists=True,
        writable=True,
        resolve_path=True,
        help="Where to store the resulting BGraph",
    ),
    mirror: str = typer.Argument(
        ..., help="Path to the mirror or the URL to AOSP source"
    ),
    branch_pattern: str = typer.Option(
        "android-*", help="Pattern to match the branches"
    ),
    workdir: Optional[Path] = typer.Option(
        None, help="Work directory (default will be a tmp directory)"
    ),
):
    """Generate BGraph's from a mirror dir."""

    mirror_path: Union[str, pathlib.Path] = bgraph.utils.clean_mirror_path(mirror)

    workdir = bgraph.builder.compose_all(mirror_path, branch_pattern, workdir)

    bgraph.builder.convert(workdir, result_dir)
    founds = len(list(result_dir.glob("*.bgraph")))
    typer.echo(f"Generated {founds} graphs.")


@app.command(name="list")
def list_command(
    directory: Path = typer.Argument(
        None,
        file_okay=False,
        dir_okay=True,
        exists=True,
        readable=True,
        resolve_path=True,
        help="The directory to search BGraph files",
    ),
    extension: Optional[str] = typer.Option(
        ".bgraph", help="Extension of the BGraph files"
    ),
):
    """
    List the BGraph already generated.
    """

    table = rich.table.Table(title="BGraph founds :")
    table.add_column("Name", justify="right")
    table.add_column("Size", justify="right")

    for bgraph_file in directory.rglob(f"*{extension}"):

        table.add_row(
            bgraph_file.name, rich.filesize.decimal(bgraph_file.stat().st_size)
        )

    console = rich.console.Console()
    console.print(table)


@app.command()
def query(
    graph_path: Path = typer.Argument(
        ...,
        file_okay=True,
        dir_okay=False,
        exists=True,
        resolve_path=True,
        readable=True,
        help="BGraph to query",
    ),
    target: str = typer.Option(None, help="Target to query"),
    src: str = typer.Option(None, help="Source file"),
    dependency: str = typer.Option(None, "--dep", help="Dependecy"),
    out: OutChoice = typer.Option(OutChoice.TXT, help="Output format"),
):
    """Query a BGraph."""

    defined = [target is not None, src is not None, dependency is not None]
    if defined.count(True) > 1:
        typer.echo("Define only one of src/target/dependency")
        raise typer.Exit(code=1)

    try:
        graph = bgraph.viewer.load_graph(graph_path)
    except bgraph.exc.BGraphLoadingException:
        typer.echo("Unable to load the graph")
        raise typer.Exit(code=1)

    result: List[str]
    query_type: QueryType
    if target is not None:
        result = bgraph.viewer.find_sources(graph, target)
        query_type = QueryType.TARGET
        query_value = target
    elif src is not None:
        query_value, result = bgraph.viewer.find_target(graph, src)
        query_type = QueryType.SOURCE
    else:
        query_type = QueryType.DEPENDENCY
        result = bgraph.viewer.find_dependency(graph, dependency)
        query_value = dependency

    if not result:
        typer.echo("No result for request")
        raise typer.Exit(code=2)

    bgraph.viewer.format_result(graph, result, query_type, query_value, out)


@app.callback()
def main(
    verbose: bool = typer.Option(
        False, "--verbose", "-v", help="Activate verbose output"
    )
):
    """BGraph - generate and query build dependency graphes.

    BGraph is used to manipulate build dependency graphs generated from blueprint files.
    The main commands are:

        - generate : used to generates multiples graphs

        - query: used to query a previously generated graph

    To get more help, see the online documentation.
    """
    import sys
    logger.info("getrecursionlimit %d", sys.getrecursionlimit())
    sys.setrecursionlimit(20000)

    import logging
    logging.basicConfig(filename='gshell.log', encoding='utf-8', filemode='w', level=logging.DEBUG)

    gshell.debug = True

    logging_level = logging.INFO
    if verbose:
        logging_level = logging.DEBUG

    logging.getLogger().setLevel(logging_level)
